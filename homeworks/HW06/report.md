# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-01.csv`
- Размер: 30 столбцов и 12000 строк
- Целевая переменная: `target` 0 - 0.676583, 1 - 0.323417
- Признаки: int64

## 2. Protocol

- Разбиение: train/test 0,2 `random_state` = 42
- Подбор: Выполнен только на обучающей выборке с использованием 5-фолдовой кросс-валидации (cv=5) через GridSearchCV.
- Метрики: 
Accuracy — общая доля правильных предсказаний.
F1-score — гармоническое среднее precision и recall; важен при возможном дисбалансе.
ROC-AUC — площадь под ROC-кривой; показывает, насколько хорошо модель разделяет классы независимо от порога.
Эти метрики вместе дают полную картину: ROC-AUC для выбора модели, F1 и accuracy — для интерпретации её практической полезности.
Оптимизировалась метрика ROC-AUC, так как задача — бинарная классификация, а ROC-AUC устойчива к дисбалансу классов и оценивает качество ранжирования, а не только точность предсказаний.

## 3. Models

Опишите, какие модели сравнивали и какие гиперпараметры подбирали.

Минимум:

- DummyClassifier
- LogisticRegression 'scaler', StandardScaler(),
    'logreg', LogisticRegression(max_iter=1000, random_state=42)
- DecisionTreeClassifier 'max_depth': [3, 5, 7],
    'min_samples_leaf': [5, 10, 20],
- RandomForestClassifier 'n_estimators': [50, 100],
    'max_depth': [3, 5, 7, 10],
    'min_samples_leaf': [2, 5, 10],
    'max_features': ['sqrt', 'log2']
- AdaBoost 'n_estimators': [20, 35, 50, 100],
    'learning_rate': [0.01, 0.1, 1.0]
- GradientBoosting 'n_estimators': [30, 50, 70, 100],
    'learning_rate': [0.05, 0.1],
    'max_depth': [3, 5],
    'min_samples_leaf': [5, 10]


## 4. Results

- Таблица/список финальных метрик на test по всем моделям
                       Модель  Accuracy   ROC-AUC        F1
0  DummyClassifier (бейзлайн)  0.676667  0.676667  0.000000
1          LogisticRegression  0.827500  0.874678  0.708039
2      DecisionTreeClassifier  0.854583  0.894559  0.757133
3      RandomForestClassifier  0.908333  0.959049  0.845722
4          AdaBoostClassifier  0.836250  0.899414  0.723434
5  GradientBoostingClassifier  0.922500  0.967542  0.874832
- Победитель (по ROC-AUC) GradientBoostingClassifier

## 5. Analysis

- Устойчивость: устойчиво
- Ошибки: 
[[1564   60]
 [ 126  650]]
- Интерпретация: 
=== Top-15 признаков по Permutation Importance ===
   feature  importance
17   num18    0.076092
18   num19    0.070299
6    num07    0.039682
3    num04    0.017626
23   num24    0.016316
19   num20    0.011471
21   num22    0.009448
0    num01    0.009332
13   num14    0.007057
15   num16    0.005932
16   num17    0.005569
20   num21    0.004404
7    num08    0.003049
1    num02    0.002577
12   num13    0.002027

## 6. Conclusion

Деревья без контроля сложности быстро переобучаются, но даже с max_depth и min_samples_leaf уступают ансамблям.
Ансамбли (Random Forest, Boosting) дают стабильное и высокое качество, причём Random Forest проще в настройке и менее склонен к переобучению на шуме.
Честный ML-протокол (CV на train, test — один раз) критически важен: без него легко получить оптимистичную оценку.
ROC-AUC — надёжный критерий выбора модели в бинарной классификации, особенно при возможном дисбалансе.
Permutation importance помогает отделить действительно значимые признаки от шума — даже в "чёрном ящике" вроде Random Forest.
Базовая модель (Dummy) необходима: она показывает, что даже "глупая" стратегия может давать 50% accuracy, и всё должно быть лучше этого.
