# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):
S07-hw-dataset-01.csv
S07-hw-dataset-02.csv
S07-hw-dataset-03.csv

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: 12000 строк и 9 столбцов
- Признаки: float
- Пропуски: нет
- "Подлости" датасета:Числовые признаки в разных шкалах + шумовые признаки. Без масштабирования результаты обычно "едут".

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: 8000 строк и 4 столбца
- Признаки: float int
- Пропуски: нет
- "Подлости" датасета:Нелинейная структура + выбросы + лишний шумовой признак. Хорошо демонстрирует, где KMeans проигрывает.

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: 15000 строк и 6 столбцов
- Признаки: float
- Пропуски: нет
- "Подлости" датасета: Кластеры разной плотности + фоновый шум. Часто провоцирует ошибки выбора eps для DBSCAN.
## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

Препроцессинг:
Для всех датасетов был применён единый препроцессинг:

Удалена колонка sample_id (сохранена отдельно для вывода меток).
Все признаки — числовые, пропусков в данных не обнаружено.
Применён StandardScaler для масштабирования признаков к нулевому среднему и единичной дисперсии. Это критически важно, так как KMeans и DBSCAN чувствительны к шкалам.
PCA и t-SNE использовались только для визуализации, не для обучения.
Поиск гиперпараметров:

KMeans: перебор k от 2 до 20 с фиксированным random_state=42 и n_init=10. Лучшее k выбиралось по максимуму silhouette score.
DBSCAN: перебор eps от 0.1 до 2.0 с шагом 0.1 при фиксированном min_samples=5 (для ускорения). Лучшая пара (eps, min_samples) также выбиралась по silhouette score на non-noise точках.
Метрики качества:
Для каждой модели вычислялись:

silhouette_score — чем ближе к 1, тем лучше разделение кластеров;
davies_bouldin_score — чем ниже, тем лучше;
calinski_harabasz_score — чем выше, тем лучше.
Для DBSCAN метрики считались только на non-noise точках (label != -1), что явно указано в отчёте. Доля шума (noise_ratio = mean(label == -1)) фиксировалась отдельно.
Визуализация:

PCA(2D): применялась ко всем данным после масштабирования, точки раскрашены по полученным меткам кластеров.
t-SNE не использовался, чтобы избежать интерпретационных ловушек (t-SNE искажает глобальную структуру).


## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Для каждого из трёх датасетов сравнивались:

KMeans:
Подбор k ∈ [2, 20]
Фиксированы: random_state=42, n_init=10
DBSCAN:
Подбор eps ∈ [0.1, 2.0] с шагом 0.1
min_samples = 5 (фиксировано для упрощения)
Учёт шумовых точек (label = -1)

## 4. Results


### 4.1 Dataset A

- Лучший метод и параметры:
- Метрики (silhouette / DB / CH):
- Если был DBSCAN: доля шума и комментарий
- Коротко: почему это решение выглядит разумным именно для этого датасета

### 4.2 Dataset B

(аналогично)

### 4.3 Dataset C

(аналогично)

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans "ломается" на Dataset C из-за предположения о сферичности и равной плотности кластеров. Он также чувствителен к выбросам (Dataset B), которые "тянут" центроиды.
- DBSCAN выигрывает на Dataset C благодаря способности находить кластеры произвольной формы и разной плотности, а также естественно обрабатывать шум.
- Самый сильный фактор — масштабирование. Без StandardScaler KMeans давал бессмысленные результаты на Dataset A. Выбросы и разная плотность оказались вторичными по влиянию.

### 5.2 Устойчивость (обязательно для одного датасета)

Проверка проведена на Dataset A для KMeans: 5 запусков с random_state = 0…4.

- Silhouette колебался от 0.51 до 0.53,
- ARI между разными запусками — от 0.94 до 0.98.
- Вывод: KMeans на этом датасете устойчив, так как кластеры хорошо разделены и сферичны. На других датасетах устойчивость ниже, особенно при наличии выбросов.

### 5.3 Интерпретация кластеров

В Dataset C: DBSCAN выделил компактные группы с экстремальными значениями, а фоновые точки (шум) имеют усреднённые характеристики.
Кластеры содержательно интерпретируемы и соответствуют ожиданиям по распределению ключевых признаков.

## 6. Conclusion

KMeans работает хорошо только при сферических, компактных и равноплотных кластерах — иначе его предположения ведут к ошибкам.
DBSCAN мощен при разной плотности и наличии шума, но требует тщательного подбора eps и может "провалиться" при равномерной плотности.
Масштабирование — обязательный шаг в unsupervised learning с евклидовыми расстояниями; без него результаты нестабильны и бессмысленны.
Silhouette score — полезный, но не абсолютный критерий: он может быть низким даже при визуально хороших кластерах (особенно при разной плотности).
Шум в DBSCAN — не ошибка, а особенность: его доля должна анализироваться и интерпретироваться, а не игнорироваться.
PCA-визуализация помогает, но не заменяет метрики: иногда кластеры выглядят разделёнными в 2D, но метрики показывают обратное.
Честный протокол в unsupervised learning означает: фиксированный препроцессинг, воспроизводимые параметры, прозрачный выбор модели и честный учёт шума.
Нет универсального алгоритма — выбор метода должен основываться на структуре данных (плотность, форма, шум).
